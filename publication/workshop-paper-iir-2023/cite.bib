@inproceedings{DBLP:conf/iir/BarberaSRMM23,
	title        = {{Fact-Checking at Scale with Crowdsourcing: Experiments and Lessons Learned}},
	author       = {La Barbera, David and Soprano, Michael and Roitero, Kevin and Maddalena, Eddy and Mizzaro, Stefano},
	year         = 2023,
	month        = 8,
	day          = 5,
	booktitle    = {Proceedings of the 13th Italian Information Retrieval Workshop},
	series       = {IIR 2023},
	location     = {Pisa, Italy},
	publisher    = {CEUR-WS.org},
	series       = {{CEUR} Workshop Proceedings},
	volume       = 3448,
	pages        = {85--90},
	url          = {https://ceur-ws.org/Vol-3448/paper-18.pdf},
	editor       = {Nardini, Franco Maria and Tonelotto, Nicola and Faggioli, Guglielmo and Ferrara, Antonio},
    keywords     = {crowdsourcing, human computation, fact-checking, misinformation, truthfulness assessment},
    abstract     = {In this paper, we present our journey in exploring the use of crowdsourcing for fact-checking. We discuss our early experiments aimed towards the identification of the best possible setting for misinformation assessment using crowdsourcing. Our results indicate that the crowd can effectively address misinformation at scale, showing some degree of correlation with experts. We also highlight the influence of worker background on the quality of truthfulness assessments.}
}