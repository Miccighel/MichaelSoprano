---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'Crowdsourcing Statement Classification to Enhance Information Quality Prediction'
subtitle: ''
summary: ''
authors:
- Jaspreet Singh
- Michael Soprano
- Kevin Roitero
- Davide Ceolin
tags:
- crowdsourcing annotation
- information quality assessment
- argument type identification
categories: []
date: '2024-06-22'
lastmod: 2024-06-22T17:46:00+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2024-06-22T14:36:35.998652Z'
publication_types:
- '1'
abstract: 'Due to their relatively low cost and ability to scale, crowdsourcing based approaches are widely used to collect a large amount of human annotated data. To this aim, multiple crowdsourcing platforms exist, where requesters can upload tasks and workers can carry them out and obtain payment in return. Such platforms share a task design and deploy workflow that is often counter-intuitive and cumbersome. To address this issue, we propose Crowd_Frame, a simple and complete framework which allows to develop and deploy diverse types of complex crowdsourcing tasks in an easy and customizable way. We show the abilities of the proposed framework and we make it available to researchers and practitioners.'
publication: '*Proceedings of the 6th Multidisciplinary International Symposium on Disinformation in Online Open Media (MISDOOM 2024). MÃ¼nster, Germany. Accepted for publication on June 21, 2024.'
---
