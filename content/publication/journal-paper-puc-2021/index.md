---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'The Many Dimensions of Truthfulness: Crowdsourcing Misinformation Assessments on a Multidimensional Scale'
subtitle: ''
summary: ''
authors:
- Kevin Roitero
- Michael Soprano
- Beatrice Portelli
- Massimiliano De Luise
- Vincenzo Della Mea
- Giuseppe Serra
- Stefano Mizzaro
- Gianluca Demartini
  tags:
- truthfulness
- crowdsourcing
- misinformation
- covid-19
  categories: []
  date: '2021-09-16'
  lastmod: 2021-09-15T15:00:00+01:00
  featured: false
  draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
caption: ''
focal_point: ''
preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-09-15T15:00:00+01:00'
publication_types:
- '2'
  abstract: 'Recently, the misinformation problem has been addressed with a crowdsourcing-based approach: to assess the truthfulness of a statement, instead of relying on a few experts, a crowd of non-expert is exploited. We study whether crowdsourcing is an effective and reliable method to assess truthfulness during a pandemic, targeting statements related to COVID-19, thus addressing (mis)information that is both related to a sensitive and personal issue and very recent as compared to when the judgment is done. In our experiments, crowd workers are asked to assess the truthfulness of statements, and to provide evidence for the assessments. Besides showing that the crowd is able to accurately judge the truthfulness of the statements, we report results on workers' behavior, agreement among workers, effect of aggregation functions, of scales transformations, and of workers background and bias. We perform a longitudinal study by re-launching the task multiple times with both novice and experienced workers, deriving important insights on how the behavior and quality change over time. Our results show that workers are able to detect and objectively categorize online (mis)information related to COVID-19; both crowdsourced and expert judgments can be transformed and aggregated to improve quality; worker background and other signals (e.g., source of information, behavior) impact the quality of the data. The longitudinal study demonstrates that the time-span has a major effect on the quality of the judgments, for both novice and experienced workers. Finally, we provide an extensive failure analysis of the statements misjudged by the crowd-workers.'
  publication: '*Personal and Ubiquitous Computing, September 2021. Journal Rank: Scimago Q2 (2020)*'
  doi: 10.1145/3239573
---
