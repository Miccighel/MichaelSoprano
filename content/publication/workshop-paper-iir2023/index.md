---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Fact-Checking at Scale with Crowdsourcing Experiments and Lessons Learned
subtitle: ''
summary: ''
authors:
- David La Barbera
- Michael Soprano
- Kevin Roitero
- Eddy Maddalena
- Stefano Mizzaro
tags:
- crowdsourcing
- human computation
- fact-checking
- misinformation
- truthfulness assessment
categories: []
date: '2023-08-05'
lastmod: 2023-08-05T15:30:30+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-08-05T15:30:30+01:00'
publication_types:
- '3'
abstract: 'In this paper, we present our journey in exploring the use of crowdsourcing for fact-checking. We discuss our early experiments aimed towards the identification of the best possible setting for misinformation assessment using crowdsourcing. Our results indicate that the crowd can effectively address misinformation at scale, showing some degree of correlation with experts. We also highlight the influence of worker background on the quality of truthfulness assessments.'
publication: '*Proceedings of the 13th Italian Information Retrieval Workshop.*'
url_pdf: https://ceur-ws.org/Vol-3448/paper-18.pdf
---
